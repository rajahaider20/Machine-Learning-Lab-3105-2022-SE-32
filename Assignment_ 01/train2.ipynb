{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d20f09",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T15:37:12.789947Z",
     "iopub.status.busy": "2025-03-04T15:37:12.789601Z",
     "iopub.status.idle": "2025-03-04T15:37:12.797588Z",
     "shell.execute_reply": "2025-03-04T15:37:12.796075Z"
    },
    "papermill": {
     "duration": 0.012976,
     "end_time": "2025-03-04T15:37:12.799035",
     "exception": false,
     "start_time": "2025-03-04T15:37:12.786059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/train.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c851d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T15:37:12.804468Z",
     "iopub.status.busy": "2025-03-04T15:37:12.804195Z",
     "iopub.status.idle": "2025-03-04T15:40:12.064043Z",
     "shell.execute_reply": "2025-03-04T15:40:12.062862Z"
    },
    "papermill": {
     "duration": 179.264368,
     "end_time": "2025-03-04T15:40:12.065889",
     "exception": false,
     "start_time": "2025-03-04T15:37:12.801521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 0.6882 - Val Loss: 0.6843\n",
      "Model saved!\n",
      "Epoch 2/100 - Train Loss: 0.6827 - Val Loss: 0.6775\n",
      "Model saved!\n",
      "Epoch 3/100 - Train Loss: 0.6767 - Val Loss: 0.6702\n",
      "Model saved!\n",
      "Epoch 4/100 - Train Loss: 0.6703 - Val Loss: 0.6626\n",
      "Model saved!\n",
      "Epoch 5/100 - Train Loss: 0.6644 - Val Loss: 0.6552\n",
      "Model saved!\n",
      "Epoch 6/100 - Train Loss: 0.6587 - Val Loss: 0.6485\n",
      "Model saved!\n",
      "Epoch 7/100 - Train Loss: 0.6538 - Val Loss: 0.6429\n",
      "Model saved!\n",
      "Epoch 8/100 - Train Loss: 0.6498 - Val Loss: 0.6382\n",
      "Model saved!\n",
      "Epoch 9/100 - Train Loss: 0.6455 - Val Loss: 0.6345\n",
      "Model saved!\n",
      "Epoch 10/100 - Train Loss: 0.6440 - Val Loss: 0.6318\n",
      "Model saved!\n",
      "Epoch 11/100 - Train Loss: 0.6421 - Val Loss: 0.6296\n",
      "Model saved!\n",
      "Epoch 12/100 - Train Loss: 0.6399 - Val Loss: 0.6279\n",
      "Model saved!\n",
      "Epoch 13/100 - Train Loss: 0.6401 - Val Loss: 0.6266\n",
      "Model saved!\n",
      "Epoch 14/100 - Train Loss: 0.6384 - Val Loss: 0.6255\n",
      "Model saved!\n",
      "Epoch 15/100 - Train Loss: 0.6377 - Val Loss: 0.6246\n",
      "Model saved!\n",
      "Epoch 16/100 - Train Loss: 0.6363 - Val Loss: 0.6237\n",
      "Model saved!\n",
      "Epoch 17/100 - Train Loss: 0.6363 - Val Loss: 0.6230\n",
      "Model saved!\n",
      "Epoch 18/100 - Train Loss: 0.6361 - Val Loss: 0.6224\n",
      "Model saved!\n",
      "Epoch 19/100 - Train Loss: 0.6347 - Val Loss: 0.6219\n",
      "Model saved!\n",
      "Epoch 20/100 - Train Loss: 0.6337 - Val Loss: 0.6213\n",
      "Model saved!\n",
      "Epoch 21/100 - Train Loss: 0.6346 - Val Loss: 0.6209\n",
      "Model saved!\n",
      "Epoch 22/100 - Train Loss: 0.6335 - Val Loss: 0.6204\n",
      "Model saved!\n",
      "Epoch 23/100 - Train Loss: 0.6337 - Val Loss: 0.6200\n",
      "Model saved!\n",
      "Epoch 24/100 - Train Loss: 0.6316 - Val Loss: 0.6196\n",
      "Model saved!\n",
      "Epoch 25/100 - Train Loss: 0.6330 - Val Loss: 0.6193\n",
      "Model saved!\n",
      "Epoch 26/100 - Train Loss: 0.6334 - Val Loss: 0.6190\n",
      "Model saved!\n",
      "Epoch 27/100 - Train Loss: 0.6313 - Val Loss: 0.6187\n",
      "Model saved!\n",
      "Epoch 28/100 - Train Loss: 0.6309 - Val Loss: 0.6184\n",
      "Model saved!\n",
      "Epoch 29/100 - Train Loss: 0.6327 - Val Loss: 0.6181\n",
      "Model saved!\n",
      "Epoch 30/100 - Train Loss: 0.6301 - Val Loss: 0.6178\n",
      "Model saved!\n",
      "Epoch 31/100 - Train Loss: 0.6318 - Val Loss: 0.6176\n",
      "Model saved!\n",
      "Epoch 32/100 - Train Loss: 0.6302 - Val Loss: 0.6173\n",
      "Model saved!\n",
      "Epoch 33/100 - Train Loss: 0.6309 - Val Loss: 0.6172\n",
      "Model saved!\n",
      "Epoch 34/100 - Train Loss: 0.6310 - Val Loss: 0.6170\n",
      "Model saved!\n",
      "Epoch 35/100 - Train Loss: 0.6292 - Val Loss: 0.6167\n",
      "Model saved!\n",
      "Epoch 36/100 - Train Loss: 0.6293 - Val Loss: 0.6165\n",
      "Model saved!\n",
      "Epoch 37/100 - Train Loss: 0.6290 - Val Loss: 0.6163\n",
      "Model saved!\n",
      "Epoch 38/100 - Train Loss: 0.6287 - Val Loss: 0.6162\n",
      "Model saved!\n",
      "Epoch 39/100 - Train Loss: 0.6283 - Val Loss: 0.6160\n",
      "Model saved!\n",
      "Epoch 40/100 - Train Loss: 0.6283 - Val Loss: 0.6158\n",
      "Model saved!\n",
      "Epoch 41/100 - Train Loss: 0.6276 - Val Loss: 0.6156\n",
      "Model saved!\n",
      "Epoch 42/100 - Train Loss: 0.6276 - Val Loss: 0.6155\n",
      "Model saved!\n",
      "Epoch 43/100 - Train Loss: 0.6282 - Val Loss: 0.6154\n",
      "Model saved!\n",
      "Epoch 44/100 - Train Loss: 0.6278 - Val Loss: 0.6153\n",
      "Model saved!\n",
      "Epoch 45/100 - Train Loss: 0.6274 - Val Loss: 0.6152\n",
      "Model saved!\n",
      "Epoch 46/100 - Train Loss: 0.6284 - Val Loss: 0.6151\n",
      "Model saved!\n",
      "Epoch 47/100 - Train Loss: 0.6275 - Val Loss: 0.6150\n",
      "Model saved!\n",
      "Epoch 48/100 - Train Loss: 0.6283 - Val Loss: 0.6149\n",
      "Model saved!\n",
      "Epoch 49/100 - Train Loss: 0.6272 - Val Loss: 0.6148\n",
      "Model saved!\n",
      "Epoch 50/100 - Train Loss: 0.6271 - Val Loss: 0.6147\n",
      "Model saved!\n",
      "Epoch 51/100 - Train Loss: 0.6270 - Val Loss: 0.6146\n",
      "Model saved!\n",
      "Epoch 52/100 - Train Loss: 0.6255 - Val Loss: 0.6144\n",
      "Model saved!\n",
      "Epoch 53/100 - Train Loss: 0.6254 - Val Loss: 0.6143\n",
      "Model saved!\n",
      "Epoch 54/100 - Train Loss: 0.6270 - Val Loss: 0.6143\n",
      "Model saved!\n",
      "Epoch 55/100 - Train Loss: 0.6266 - Val Loss: 0.6142\n",
      "Model saved!\n",
      "Epoch 56/100 - Train Loss: 0.6262 - Val Loss: 0.6141\n",
      "Model saved!\n",
      "Epoch 57/100 - Train Loss: 0.6257 - Val Loss: 0.6140\n",
      "Model saved!\n",
      "Epoch 58/100 - Train Loss: 0.6249 - Val Loss: 0.6140\n",
      "Model saved!\n",
      "Epoch 59/100 - Train Loss: 0.6251 - Val Loss: 0.6139\n",
      "Model saved!\n",
      "Epoch 60/100 - Train Loss: 0.6248 - Val Loss: 0.6138\n",
      "Model saved!\n",
      "Epoch 61/100 - Train Loss: 0.6257 - Val Loss: 0.6138\n",
      "Model saved!\n",
      "Epoch 62/100 - Train Loss: 0.6256 - Val Loss: 0.6137\n",
      "Model saved!\n",
      "Epoch 63/100 - Train Loss: 0.6253 - Val Loss: 0.6136\n",
      "Model saved!\n",
      "Epoch 64/100 - Train Loss: 0.6249 - Val Loss: 0.6136\n",
      "Model saved!\n",
      "Epoch 65/100 - Train Loss: 0.6246 - Val Loss: 0.6135\n",
      "Model saved!\n",
      "Epoch 66/100 - Train Loss: 0.6240 - Val Loss: 0.6135\n",
      "Model saved!\n",
      "Epoch 67/100 - Train Loss: 0.6248 - Val Loss: 0.6134\n",
      "Model saved!\n",
      "Epoch 68/100 - Train Loss: 0.6254 - Val Loss: 0.6134\n",
      "Model saved!\n",
      "Epoch 69/100 - Train Loss: 0.6242 - Val Loss: 0.6134\n",
      "Model saved!\n",
      "Epoch 70/100 - Train Loss: 0.6240 - Val Loss: 0.6133\n",
      "Model saved!\n",
      "Epoch 71/100 - Train Loss: 0.6235 - Val Loss: 0.6133\n",
      "Model saved!\n",
      "Epoch 72/100 - Train Loss: 0.6254 - Val Loss: 0.6132\n",
      "Model saved!\n",
      "Epoch 73/100 - Train Loss: 0.6244 - Val Loss: 0.6132\n",
      "Model saved!\n",
      "Epoch 74/100 - Train Loss: 0.6235 - Val Loss: 0.6132\n",
      "Model saved!\n",
      "Epoch 75/100 - Train Loss: 0.6239 - Val Loss: 0.6131\n",
      "Model saved!\n",
      "Epoch 76/100 - Train Loss: 0.6242 - Val Loss: 0.6131\n",
      "Model saved!\n",
      "Epoch 77/100 - Train Loss: 0.6244 - Val Loss: 0.6130\n",
      "Model saved!\n",
      "Epoch 78/100 - Train Loss: 0.6236 - Val Loss: 0.6130\n",
      "Model saved!\n",
      "Epoch 79/100 - Train Loss: 0.6230 - Val Loss: 0.6130\n",
      "Model saved!\n",
      "Epoch 80/100 - Train Loss: 0.6230 - Val Loss: 0.6129\n",
      "Model saved!\n",
      "Epoch 81/100 - Train Loss: 0.6230 - Val Loss: 0.6129\n",
      "Model saved!\n",
      "Epoch 82/100 - Train Loss: 0.6228 - Val Loss: 0.6128\n",
      "Model saved!\n",
      "Epoch 83/100 - Train Loss: 0.6224 - Val Loss: 0.6128\n",
      "Model saved!\n",
      "Epoch 84/100 - Train Loss: 0.6228 - Val Loss: 0.6128\n",
      "Model saved!\n",
      "Epoch 85/100 - Train Loss: 0.6225 - Val Loss: 0.6127\n",
      "Model saved!\n",
      "Epoch 86/100 - Train Loss: 0.6228 - Val Loss: 0.6127\n",
      "Model saved!\n",
      "Epoch 87/100 - Train Loss: 0.6232 - Val Loss: 0.6127\n",
      "Model saved!\n",
      "Epoch 88/100 - Train Loss: 0.6228 - Val Loss: 0.6127\n",
      "Model saved!\n",
      "Epoch 89/100 - Train Loss: 0.6230 - Val Loss: 0.6126\n",
      "Model saved!\n",
      "Epoch 90/100 - Train Loss: 0.6227 - Val Loss: 0.6126\n",
      "Model saved!\n",
      "Epoch 91/100 - Train Loss: 0.6226 - Val Loss: 0.6126\n",
      "Model saved!\n",
      "Epoch 92/100 - Train Loss: 0.6224 - Val Loss: 0.6126\n",
      "Model saved!\n",
      "Epoch 93/100 - Train Loss: 0.6223 - Val Loss: 0.6125\n",
      "Model saved!\n",
      "Epoch 94/100 - Train Loss: 0.6228 - Val Loss: 0.6125\n",
      "Model saved!\n",
      "Epoch 95/100 - Train Loss: 0.6221 - Val Loss: 0.6125\n",
      "Model saved!\n",
      "Epoch 96/100 - Train Loss: 0.6221 - Val Loss: 0.6124\n",
      "Model saved!\n",
      "Epoch 97/100 - Train Loss: 0.6231 - Val Loss: 0.6124\n",
      "Model saved!\n",
      "Epoch 98/100 - Train Loss: 0.6217 - Val Loss: 0.6124\n",
      "Model saved!\n",
      "Epoch 99/100 - Train Loss: 0.6231 - Val Loss: 0.6124\n",
      "Epoch 100/100 - Train Loss: 0.6222 - Val Loss: 0.6124\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ensure the directory for saving preprocessors exists\n",
    "preprocessor_dir = \"./preprocessor\"\n",
    "os.makedirs(preprocessor_dir, exist_ok=True)\n",
    "\n",
    "# =============================\n",
    "# STEP 1: LOAD AND PREPROCESS TRAINING DATA\n",
    "# =============================\n",
    "\n",
    "# Load dataset\n",
    "train_file_path = \"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\"\n",
    "df = pd.read_csv(train_file_path)\n",
    "\n",
    "# List of selected columns + target column\n",
    "selected_columns = [\n",
    "    \"prim_disease_hct\", \"hla_match_b_low\", \"prod_type\",\n",
    "    \"year_hct\", \"obesity\", \"donor_age\", \"prior_tumor\", \"gvhd_proph\",\n",
    "    \"sex_match\", \"comorbidity_score\", \"karnofsky_score\", \"donor_related\",\n",
    "    \"age_at_hct\", \"efs\"  # Target column\n",
    "]\n",
    "\n",
    "# Keep only the selected columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target from numerical list\n",
    "target = \"efs\"\n",
    "if target in num_cols:\n",
    "    num_cols.remove(target)\n",
    "\n",
    "# Handle missing values\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# Encoding categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(df[cat_cols])\n",
    "cat_feature_names = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Convert encoded categories to DataFrame\n",
    "df_encoded = pd.DataFrame(encoded_cats, columns=cat_feature_names)\n",
    "\n",
    "# Drop original categorical columns and merge encoded ones\n",
    "df = df.drop(columns=cat_cols)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Save preprocessors for inference\n",
    "joblib.dump(num_imputer, os.path.join(preprocessor_dir, \"num_imputer.pkl\"))\n",
    "joblib.dump(cat_imputer, os.path.join(preprocessor_dir, \"cat_imputer.pkl\"))\n",
    "joblib.dump(encoder, os.path.join(preprocessor_dir, \"encoder.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(preprocessor_dir, \"scaler.pkl\"))\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# =============================\n",
    "# STEP 2: DEFINE THE NEURAL NETWORK\n",
    "# =============================\n",
    "\n",
    "class EFSModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EFSModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "model = EFSModel(input_size).to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# =============================\n",
    "# STEP 3: TRAIN THE MODEL\n",
    "# =============================\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to the appropriate device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to the appropriate device\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/efs_model.pth\")\n",
    "        print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c65cb",
   "metadata": {
    "papermill": {
     "duration": 0.007014,
     "end_time": "2025-03-04T15:40:12.082592",
     "exception": false,
     "start_time": "2025-03-04T15:40:12.075578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 184.694463,
   "end_time": "2025-03-04T15:40:14.686446",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-04T15:37:09.991983",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
